{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ingestion process** refers to the workflow in which data is acquired, processed, and stored in a system, such as a database or knowledge base, to be subsequently used in applications like machine learning or search.\n",
    "\n",
    "In the context of the code:\n",
    "1. **Data Scraping**: The content of specified web pages is acquired (in this case, with the `scrape` function) and transformed into a machine-readable format.\n",
    "2. **Embedding Generation**: The content extracted from each document is processed with a machine learning model (`generateEmbedding`) to generate vector representations (embeddings). These vectors semantically represent the data, making them useful for activities like search, clustering, or classification.\n",
    "3. **Collection Creation**: A dedicated area is prepared in the database (`createCollection`) to preserve the processed data.\n",
    "4. **Data Loading**: The data, now enriched with embeddings and other structured information, is loaded into the database (`uploadData`), where it can be used for activities like **Retrieval-Augmented Generation (RAG)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "import { createCollection, uploadData} from \"./lib/db\"; //database utility functions for creating collections and uploading data\n",
    "import { generateEmbedding } from \"./lib/openai\";  //utility function for generating embeddings\n",
    "import { scrape } from \"./lib/scrape\";  //import web scraping utility function\n",
    "\n",
    "const urls = [ \n",
    "    \"https://en.wikipedia.org/wiki/Formula_One\",\n",
    "    \"https://en.wikipedia.org/wiki/George_Russel_(racing_driver)\",  //add more urls here to expand the RAG knowledge base\n",
    "];\n",
    "\n",
    "async function ingest() {\n",
    "    let chunks: { text: string, $vector: number [], url: string } [] = []; // Initialize an empty array to store processed data chunks\n",
    "    await (Promise.all(urls.map(async url => {      // Process all URLs concurrently using Promise.all\n",
    "        let data = await scrape(url);           //scrape webpages at the given url\n",
    "\n",
    "        const embeddings = await Promise.all(data.map(async (doc, index) => {    //generate embeddings for each scraped document\n",
    "            const embedding = await generateEmbedding(doc.pageContent);   //Use OpenAI to generate an embedding for the document content \n",
    "            return embedding;\n",
    "        }));\n",
    "        \n",
    "        //Combine the scraped data and corresponding embeddings into chunks\n",
    "        chunks = chunks.concat( data.map (( doc, index) => {\n",
    "            return {\n",
    "                text: doc.pageContent,  //main content of the webpage\n",
    "                $vector: embeddings[index].data[0].embedding, //content generated embedding vector\n",
    "                url: url //source url\n",
    "            }\n",
    "        }));\n",
    "    })));\n",
    "\n",
    "    await createCollection();   //create collection in the database to store processed data\n",
    "\n",
    "    // Upload the processed chunks to the knowledge base\n",
    "    await uploadData(chunks.map((doc, index)=>{\n",
    "        return {\n",
    "            $vector: doc.$vector,  //embedding vector\n",
    "            text: doc.text,        //content of the webpage\n",
    "            source: doc.url        //source url\n",
    "        }\n",
    "    }));   //upload data to the knowledge base\n",
    "}\n",
    "\n",
    "ingest();  //run the ingestion process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping web pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "import playwright from \"playwright\";  //import playwright for web scraping   \n",
    "import { RecursiveCharacterTextSplitter } from \"langchain/text_splitter\";\n",
    "\n",
    "export async function scrape(url: string) {\n",
    "\n",
    "    const browser = await playwright.chromium.launch();  //launch a chromium browser instance\n",
    "\n",
    "    const context = await browser.newContext();  //create a new browser context\n",
    "\n",
    "    const page = await context.newPage(); \n",
    "\n",
    "    await page.goto(url);\n",
    "\n",
    "    const text = await page.innerText(\"body\");  //extract text content from the webpage\n",
    "\n",
    "    text.replace(/\\n/g, \" \");  //replace newline characters with spaces\n",
    "\n",
    "    await browser.close();\n",
    "\n",
    "    //split the text into smaller chunks using the RecursiveCharacterTextSplitter\n",
    "\n",
    "    const splitter = new RecursiveCharacterTextSplitter({\n",
    "        chunksize: 512,\n",
    "        chunkoverlap: 100,\n",
    "    });\n",
    "\n",
    "    const output = await splitter.createDocuments([text]);  //split the text into smaller chunks\n",
    "\n",
    "    return output;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "import OpenAI from 'openai';\n",
    "\n",
    "const client = new OpenAI({\n",
    "    apiKey: \"API_KEY\",\n",
    "});\n",
    "\n",
    "export async function generateEmbedding(text: string) {\n",
    "    const embedding = await client.embeddings.create({\n",
    "        model: \"text-embedding-ada-02\",\n",
    "        input: text,\n",
    "    })\n",
    "\n",
    "    return embedding;\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a vector database collection called f1gpt to store the retrieved info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "import { DataAPIClient } from \"@datastax/astra-db-ts\"\n",
    "\n",
    "const client = new DataAPIClient('TOKEN');\n",
    "const db = client.db('DB_URL');\n",
    "const collection = db.collection('f1gpt');\n",
    "\n",
    "export async function createCollection(){\n",
    "    const res = await db.createCollection('f1gpt', {\n",
    "        vector: { \n",
    "            dimension: 1536, //(corresponds to the embedding vector dimension of the model)\n",
    "            \n",
    "            metric: \"dot_product\"\n",
    "        }\n",
    "});\n",
    "return res;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading data to the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "export async function uploadData(data: {\n",
    "    $vector: number[],\n",
    "    text: string\n",
    "}[]) {\n",
    "    return await collection.insertMany(data);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 steps process to answering the questions:\n",
    "1) Using existing \"generateEmbedding\" function\n",
    "2) Querying the database\n",
    "3) Generating a response to return to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "import { queryDatabase } from \"./lib/db\";\n",
    "import { generateEmbedding, generateResponse } from \"./lib/openai\";\n",
    "\n",
    "async function askQuestion(question: string) {\n",
    "    const embedding = await generateEmbedding(question);  //generate an embedding for the question\n",
    "    const queryRes = await queryDatabase(embedding.data[0].embedding);  //query the database with the generated embedding\n",
    "    const response = generateResponse(question, queryRes.map((doc) => doc.text));  //generate a response based on the query result\n",
    "    \n",
    "    return response;\n",
    "}   \n",
    "\n",
    "askQuestion(\"Why are George Russell and Max Verstappen arguing after Qatar 2024?\").then((res) => {\n",
    "    console.log(res);\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the embedding for the user has been generated, this function is used to query the database for similar records in order to answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "export async function queryDatabase(query: number[]){\n",
    "    const res = await collection.find(null, {\n",
    "        sort: {\n",
    "            $vector: query\n",
    "        },\n",
    "        limit: 10\n",
    "    }).toArray();\n",
    "    return res;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an LLM (gpt 4o in this case) a response can be generated basing on the up to date knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "export async function generateResponse(question: string, context: string[]){\n",
    "    const response = await client.chat.completions.create({\n",
    "        model:\"gpt-4o\",\n",
    "        messages: [{\n",
    "            role: \"user\",               //role prompting the question\n",
    "            content: 'You are an expert in Formula 1 racing. You need to answer this question using the context provided. Do not mention that you have been provided with the context. QUESTION: ${ question }. CONTEXT: ${ context.join(\" \")}'\n",
    "        }]\n",
    "    })\n",
    "    return response.choices[0].message.content; \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the RAG application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "askQuestion(\"Why are George Russell and Max Verstappen arguing after Qatar 2024?\").then((res)=>{\n",
    "    console.log(res);\n",
    "});"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "F1RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
